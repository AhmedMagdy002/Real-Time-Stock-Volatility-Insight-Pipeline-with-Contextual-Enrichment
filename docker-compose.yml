services:
  localstack:
    image: localstack/localstack:2.3.2
    container_name: localstack
    ports:
      - "4566:4566"
    environment:
      - SERVICES=s3

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  spark:
    image: jupyter/pyspark-notebook:spark-3.4.1
    container_name: spark
    ports:
      - "8888:8888"
    volumes:
      - ./work:/home/jovyan/work
      - ./ivy2-cache:/home/jovyan/.ivy2
      - ./m2-cache:/home/jovyan/.m2
    depends_on:
      - kafka
      - localstack

  postgres:
    image: postgres:13
    container_name: airflow_postgres
    restart: always
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - pg_data:/var/lib/postgresql/data

  airflow:
    image: apache/airflow:2.9.1
    container_name: airflow
    restart: always
    depends_on:
      - kafka
      - localstack
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./work:/opt/airflow/work
      - ./scripts:/opt/airflow/scripts   
      - airflow_logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    ports:
      - "8081:8080"
    command: >
      bash -c "
        airflow db upgrade &&
        airflow users create --username admin --firstname Admin --lastname User --role Admin --email admin@example.com --password admin &&
        airflow scheduler & 
        airflow webserver
      "

  trino:
    image: trinodb/trino:425
    container_name: trino
    ports:
      - "8082:8080"
    volumes:
      - ./trino-config:/etc/trino
    depends_on:
      - localstack

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - trino

volumes:
  pg_data:
  airflow_logs: